==TODO unfinished==

A time series is a dataset where the values are arranged in a sequence (doesn't actually have to be time)

We are concerned with predicting the next value in the sequence

## Filling in Missing Data

Missing data can be filled in with:
- Forward fill, where you use previous values to fill in the missing value, or
- Backward fill, where you use the next values to fill in the missing value

## Validation

> [!caution]
> Can't do normal cross-validation with time series

- Cut the time series off at a given point
- Predict the next period using mean squared error

## Time Series Components

- Noise: random jitters from things we can't see
	- Noise can be generated by any distribution, but is usually gaussian in nature
- Trend: Whether it's going up or down
	- A time series is called **stationary** if it has no trend
	- A time series is **stationary** if it has a constant mean and variance
		- Use Dickey-Fuller hypothesis test to find out if it's stationary
- Seasonality: Cyclic behavior

==TODO: Check out "Separating the components" slide==

## Smoothing

- We want to remove the noise to find the "true" series
- This may be a better predictor than the actual data

### Modeling

==TODO: Take notes on this==

### Moving Average

==TODO: Take notes on this==

#### Moving Average with Exponential Smoothing

- $\alpha$ is a **smoothing factor** that takes values between 0 and 1
- It determines how fast the weight decreases for previous observations
- Don't want previous observations to contribute too much

#### Double Exponential Smoothing

- $\beta$ is the trend smoothing factor and takes values between 0 and 1
- ==TODO what is this for==

#### Triple Exponential Smoothing

==TODO takes notes on this==

## Modeling

### Auto-Regressive Model

The AR model only depends on past values (lags) to estimate future values