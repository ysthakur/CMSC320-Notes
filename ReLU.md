Rectified linear unit is an activation function

It's an alternative to sigmoid function that's more popular for [Convolutional Neural Networks](Convolutional%20Neural%20Networks.md)